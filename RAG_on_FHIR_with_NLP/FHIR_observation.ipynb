{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# RAG on FHIR: Using NLP to load Observations\n",
    "\n",
    "This notebook uses [John Snow Labs SparkNLP for Healthcare](https://www.johnsnowlabs.com/) to find blood pressure readings in clinical notes, create FHIR Observation resources, and load them as nodes in a Neo4J graph. It looks for the clinical notes in DocumentReference resources that are already in the graph. \n",
    "\n",
    "This notebook assumes you have already loaded data into the Knowledge Graph as per the notebook [FHIR_GRAPHS](https://github.com/samschifman/RAG_on_FHIR/blob/main/RAG_on_FHIR_with_KG/FHIR_GRAPHS.ipynb). This notebook is not intended to be run on its own. \n",
    "\n",
    "This notebook is intended only as an example of what could be done. It is not a full implementation. For example, it assumes the date of the DocumentReference should be the date resulting Observation, regardless of the date found in the note. \n",
    "\n",
    "## Disclaimer\n",
    "Nothing provided here is guaranteed or warrantied to work. It is provided as is and has not been tested extensively. Using this notebook is at the risk of the user. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38ecbef5930c4387"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Imports needed\n",
    "\n",
    "import json\n",
    "import os\n",
    "import base64\n",
    "\n",
    "import sparknlp_jsl\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp_display import RelationExtractionVisualizer\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Imports from other local python files\n",
    "from NEO4J_Graph import Graph\n",
    "from FHIR_to_graph import resource_to_node, resource_to_edges, flat_fhir_to_json_str, flatten_fhir, resource_name, FHIR_to_string\n",
    "\n",
    "import uuid\n",
    "import re\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c4a7d3974c433a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load License from John Snow Labs\n",
    "\n",
    "This cell loads the license for SparkNLP for Healthcare. It assumes the license is in a directory you need to add. \n",
    "\n",
    "Any method of loading the license into the environment that comes from JSL's documentation should work. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a0402b0138a3695"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('working/license/spark_nlp.json') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "os.environ.update(license_keys)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1344c33104fe8b78"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install Libraries\n",
    "\n",
    "Below is the set of libraries that worked for me. Using the latest version of these libraries failed due to some incompatibilities. However, I cannot guarantee that they will work for you exactly. You may need to fiddle with the version numbers."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f060a9e49140151"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Installing pyspark and spark-nlp\n",
    "! pip install --upgrade -q pyspark==3.4.1 spark-nlp==$PUBLIC_VERSION\n",
    "\n",
    "# Installing NLU\n",
    "! pip install --upgrade --q nlu==4.0.1rc4 --no-dependencies\n",
    "\n",
    "# Installing Spark NLP Healthcare\n",
    "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n",
    "\n",
    "# Installing Spark NLP Display Library for visualization\n",
    "! pip install -q spark-nlp-display"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e68593c96db35c8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the Spark Session\n",
    "\n",
    "This cell creates the Spark session needed to run the NLP. \n",
    "\n",
    "Again, this is what worked for me. It mostly follows JSL's documentation, but I tried several examples from them before I found one that worked on my system. However, your system may be different, so please refer to their documentation if you have problems. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "810ef12b633abe88"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = {\"spark.driver.memory\":\"16G\",\n",
    "          \"spark.kryoserializer.buffer.max\":\"2000M\",\n",
    "          \"spark.driver.maxResultSize\":\"2000M\"}\n",
    "\n",
    "print(\"Spark NLP Version :\", sparknlp.version())\n",
    "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
    "\n",
    "def start(SECRET):\n",
    "    builder = SparkSession.builder \\\n",
    "        .appName(\"Spark NLP Licensed\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\", \"16G\") \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:\"+sparknlp.version()) \\\n",
    "        .config(\"spark.jars\", \"https://pypi.johnsnowlabs.com/\"+SECRET+\"/spark-nlp-jsl-\"+sparknlp_jsl.version()+\".jar\")\n",
    "\n",
    "    return builder.getOrCreate()\n",
    "\n",
    "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params, apple_silicon=True)\n",
    "\n",
    "spark"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b7645b0a1e83675"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creat the NLP Pipeline\n",
    "\n",
    "This cell defines the NLP pipeline that will be used to find the blood pressures. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "193f34d1e47b91c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = SentenceDetectorDLModel.pretrained(\"sentence_detector_dl_healthcare\",\"en\",\"clinical/models\") \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "pos_tagger = PerceptronModel() \\\n",
    "    .pretrained(\"pos_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"pos_tag\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\",\"en\",\"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\",\"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "# NER model trained on i2b2 (sampled from MIMIC) dataset\n",
    "clinical_ner = MedicalNerModel.pretrained(\"ner_jsl\",\"en\",\"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\",\"token\",\"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\") \\\n",
    "    .setLabelCasing(\"upper\") #decide if we want to return the tags in upper or lower case\n",
    "\n",
    "ner_converter = NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\",\"token\",\"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "dependency_parser = DependencyParserModel() \\\n",
    "    .pretrained(\"dependency_conllu\", \"en\") \\\n",
    "    .setInputCols([\"sentence\", \"pos_tag\", \"token\"]) \\\n",
    "    .setOutputCol(\"dependency\")\n",
    "\n",
    "clinical_re_Model = RelationExtractionModel() \\\n",
    "    .pretrained(\"re_test_result_date\", \"en\", 'clinical/models') \\\n",
    "    .setInputCols([\"embeddings\", \"pos_tag\", \"ner_chunk\", \"dependency\"]) \\\n",
    "    .setOutputCol(\"relation\") \\\n",
    "    .setPredictionThreshold(0.0) \\\n",
    "    .setMaxSyntacticDistance(5) \\\n",
    "    .setRelationPairs([\"blood_pressure-date\", \"date-blood_pressure\"])\n",
    "\n",
    "\n",
    "nlpPipeline = Pipeline(\n",
    "    stages=[\n",
    "        documentAssembler,\n",
    "        sentenceDetector,\n",
    "        tokenizer,\n",
    "        pos_tagger,\n",
    "        word_embeddings,\n",
    "        clinical_ner,\n",
    "        ner_converter,\n",
    "        dependency_parser,\n",
    "        clinical_re_Model\n",
    "    ])\n",
    "\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e3ff7ba108eb320"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Establish Database Connection\n",
    "\n",
    "The cell connects to the Neo4J instance. It relies on several environment variables. \n",
    "\n",
    "**PLEASE NOTE**: The variable have been changed to support multiple databases in the same instance. \n",
    "\n",
    "| Variable            | Description                          | Sample Value          |\n",
    "|---------------------|--------------------------------------|-----------------------|\n",
    "| FHIR_GRAPH_URL      | Where to find the instance of Neo4j. | bolt://localhost:7687 |\n",
    "| FHIR_GRAPH_USER     | The username for the database.       | neo4j                 |\n",
    "| FHIR_GRAPH_PASSWORD | The password for the database.       | password              |\n",
    "| FHIR_GRAPH_DATABASE | The name of the database instance.   | neo4j                 |"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f550cf14515a2f93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NEO4J_URI = os.getenv('FHIR_GRAPH_URL')\n",
    "USERNAME = os.getenv('FHIR_GRAPH_USER')\n",
    "PASSWORD = os.getenv('FHIR_GRAPH_PASSWORD')\n",
    "DATABASE = os.getenv('FHIR_GRAPH_DATABASE')\n",
    "\n",
    "graph = Graph(NEO4J_URI, USERNAME, PASSWORD, DATABASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find DocumentReference Resources\n",
    "\n",
    "This cell uses Cypher to find `DocumentReference` resources already in the Knowledge Graph. \n",
    "\n",
    "To show that it is working: It then extracts the `attachment_data` and decodes the Base64. Finally it runs that through the NLP pipeline and shows the results. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "206b19d262602192"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cyoher = \"\"\"\n",
    "match (n:DocumentReference) return n\n",
    "\"\"\"\n",
    "\n",
    "document_reference_nodes = graph.query(cyoher)\n",
    "\n",
    "encoded = document_reference_nodes[0][0][0][\"content_0_attachment_data\"]\n",
    "note = base64.b64decode(encoded).decode('ascii')\n",
    "nlp = model.transform(spark.createDataFrame([[note]]).toDF(\"text\"))\n",
    "nlp.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28cfb853b5884636"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Method to Extract Blood Pressure from NLP\n",
    "\n",
    "This method is able find where in the NLP results the blood pressure string is. \n",
    "\n",
    "It then prints it from the NLP run above to prove that it is working. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91d5146fae6b99d4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_bp_str(_nlp):\n",
    "    blood_pressure_str =  _nlp.select(\n",
    "        F.explode(nlp.relation.metadata).alias('cols')\n",
    "    ).filter(\n",
    "        \"cols['entity2']='BLOOD_PRESSURE'\"\n",
    "    ).select(\n",
    "        F.expr(\"cols['chunk2']\").alias(\"bp\"),\n",
    "        F.expr(\"cols['chunk1']\").alias(\"date\"),\n",
    "    ).collect()[0]['bp']\n",
    "    return blood_pressure_str\n",
    "\n",
    "blood_pressure_str = get_bp_str(nlp)\n",
    "print(blood_pressure_str)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d20fa70bda5b5d63"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Method to Parse Blood Pressure String\n",
    "\n",
    "This method can find the numeric components of the blood pressure within the string. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "266a49187fd2af5c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def parse_bp(bp_str):\n",
    "    matches = re.match(r'[a-zA-Z ]*(\\d{1,3})/(\\d{1,3})', bp_str)\n",
    "    return int(matches.group(1)), int(matches.group(2))\n",
    "\n",
    "print(parse_bp(\"BP was 137/88 mm Hg\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "528c43afc8d5bf93"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Method to Extract Replacement Values\n",
    "\n",
    "There are number of values needed from the `DocumentReference` and `blood pressure string` to fill in the new `Observation` resource. This method consolidates finding all those values in one place. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "742520450a96e4eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_replacements(doc_ref, bp_str):\n",
    "    id = uuid.uuid4()\n",
    "    patient = doc_ref[0][\"subject_reference\"]\n",
    "    encounter = doc_ref[0][\"context_encounter_0_reference\"]\n",
    "    date_str = doc_ref[0][\"date\"]\n",
    "    systolic, diastolic = parse_bp(bp_str)\n",
    "    return id, patient, encounter, date_str, systolic, diastolic\n",
    "\n",
    "id, patient, encounter, date_str, systolic, diastolic = get_replacements(document_reference_nodes[0][0], blood_pressure_str)\n",
    "print(f'{id},  {patient},  {encounter},  {date_str}, {systolic}/{diastolic}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51e0c233c97ae258"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Method to Create Observation\n",
    "\n",
    "This cell contains a template blood pressure `Observation` resource and the method to fill it in."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76c8c2b83d6c568a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TEMPLATE_OBSERVATION = \"\"\"\n",
    "{\n",
    "        \"resourceType\": \"Observation\",\n",
    "        \"id\": \"[ID]\",\n",
    "        \"meta\": {\n",
    "          \"profile\": [\n",
    "            \"http://hl7.org/fhir/us/core/StructureDefinition/us-core-blood-pressure\"\n",
    "          ]\n",
    "        },\n",
    "        \"status\": \"final\",\n",
    "        \"category\": [\n",
    "          {\n",
    "            \"coding\": [\n",
    "              {\n",
    "                \"system\": \"http://terminology.hl7.org/CodeSystem/observation-category\",\n",
    "                \"code\": \"vital-signs\",\n",
    "                \"display\": \"Vital signs\"\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        ],\n",
    "        \"code\": {\n",
    "          \"coding\": [\n",
    "            {\n",
    "              \"system\": \"http://loinc.org\",\n",
    "              \"code\": \"85354-9\",\n",
    "              \"display\": \"Blood pressure panel with all children optional\"\n",
    "            }\n",
    "          ],\n",
    "          \"text\": \"Blood pressure panel with all children optional\"\n",
    "        },\n",
    "        \"subject\": {\n",
    "          \"reference\": \"[PATIENT]\"\n",
    "        },\n",
    "        \"encounter\": {\n",
    "          \"reference\": \"[ENCOUNTER]\"\n",
    "        },\n",
    "        \"effectiveDateTime\": \"[DATE]\",\n",
    "        \"issued\": \"[DATE]\",\n",
    "        \"component\": [\n",
    "          {\n",
    "            \"code\": {\n",
    "              \"coding\": [\n",
    "                {\n",
    "                  \"system\": \"http://loinc.org\",\n",
    "                  \"code\": \"8462-4\",\n",
    "                  \"display\": \"Diastolic Blood Pressure\"\n",
    "                }\n",
    "              ],\n",
    "              \"text\": \"Diastolic Blood Pressure\"\n",
    "            },\n",
    "            \"valueQuantity\": {\n",
    "              \"value\": [DIASTOLIC],\n",
    "              \"unit\": \"mm[Hg]\",\n",
    "              \"system\": \"http://unitsofmeasure.org\",\n",
    "              \"code\": \"mm[Hg]\"\n",
    "            }\n",
    "          },\n",
    "          {\n",
    "            \"code\": {\n",
    "              \"coding\": [\n",
    "                {\n",
    "                  \"system\": \"http://loinc.org\",\n",
    "                  \"code\": \"8480-6\",\n",
    "                  \"display\": \"Systolic Blood Pressure\"\n",
    "                }\n",
    "              ],\n",
    "              \"text\": \"Systolic Blood Pressure\"\n",
    "            },\n",
    "            \"valueQuantity\": {\n",
    "              \"value\": [SYSTOLIC],\n",
    "              \"unit\": \"mm[Hg]\",\n",
    "              \"system\": \"http://unitsofmeasure.org\",\n",
    "              \"code\": \"mm[Hg]\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "\"\"\"\n",
    "\n",
    "def create_observation(id, patient, encounter, date_str, systolic, diastolic):\n",
    "    resource = TEMPLATE_OBSERVATION\n",
    "    resource = resource.replace(\"[ID]\", id)\n",
    "    resource = resource.replace(\"[PATIENT]\", patient)\n",
    "    resource = resource.replace(\"[ENCOUNTER]\", encounter)\n",
    "    resource = resource.replace(\"[DATE]\", date_str)\n",
    "    resource = resource.replace(\"[SYSTOLIC]\", systolic)\n",
    "    resource = resource.replace(\"[DIASTOLIC]\", diastolic)\n",
    "    return resource\n",
    "\n",
    "print(create_observation(str(id), patient, encounter, date_str, str(systolic), str(diastolic)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fd784d6bf89e0c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Observation Resources \n",
    "\n",
    "This cell iterates through the list of `DocumentReferences`, runs them through NLP, and creates `Observations` for them. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da18f15fb39d9295"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "observations = []\n",
    "for doc_ref in document_reference_nodes[0]:\n",
    "    encoded = doc_ref[0][\"content_0_attachment_data\"]\n",
    "    note = base64.b64decode(encoded).decode('ascii')\n",
    "    nlp = model.transform(spark.createDataFrame([[note]]).toDF(\"text\"))\n",
    "    blood_pressure_str = get_bp_str(nlp)\n",
    "    id, patient, encounter, date_str, systolic, diastolic = get_replacements(doc_ref, blood_pressure_str)\n",
    "    observations.append(create_observation(str(id), patient, encounter, date_str, str(systolic), str(diastolic)))\n",
    "    \n",
    "print(observations)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7034d9b999a27ee6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Cypher to Add Nodes and Edges\n",
    "\n",
    "This cell iterates through the list of `Observations` created above and constructs the Cypher queries needed to add the nodes in the DB."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be7e3d1e725507c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def inferred_resource_to_node(resource):\n",
    "    resource_type = resource['resourceType']\n",
    "    flat_resource = flat_fhir_to_json_str(flatten_fhir(resource), resource_name(resource), FHIR_to_string(resource))\n",
    "    return f'CREATE (:{resource_type}:resource:inferred {flat_resource})'\n",
    "\n",
    "nodes = []\n",
    "edges = []\n",
    "dates = set() # set is used here to make sure dates are unique\n",
    "for resource_str in observations:\n",
    "    resource = json.loads(resource_str)\n",
    "    nodes.append(inferred_resource_to_node(resource))\n",
    "    node_edges, node_dates = resource_to_edges(resource)\n",
    "    edges += node_edges\n",
    "    dates.update(node_dates)\n",
    "    \n",
    "print(nodes)\n",
    "print(edges)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8d318f70ef8a902"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Nodes in DB\n",
    "\n",
    "This cell creates the nodes and edges in the DB."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7054f2d765330b62"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    graph.query(node)\n",
    "\n",
    "for edge in edges:\n",
    "    try:\n",
    "        graph.query(edge)\n",
    "    except:\n",
    "        print(f'Failed to create edge: {edge}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcbd80cf80c38e4e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TODO: Add to embedding index\n",
    "\n",
    "It is left to you to add the new nodes to the vector/embedding index if you want to use them in RAG. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0d7d4982bab2c75"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Disclaimer:** Nothing provided here is guaranteed or warrantied to work. It is provided as is and has not been tested extensively. Using this notebook is at the risk of the user. \n",
    "\n",
    "Copyright &copy; 2024 Sam Schifman"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74946243c3c64a6d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
